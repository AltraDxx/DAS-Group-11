---
title: "Project2"
author: "Group-11"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: default
prefer-html: true
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
---

```{r}
library(tidyverse)  
library(moderndive)  
library(gapminder)   
library(sjPlot)      
library(jtools)      
library(GGally)      
library(gt)          
library(gridExtra)   
library(knitr)  
library(patchwork)
library(broom)
library(MASS)
library(janitor)
library(pscl)
```

# Data Visulization

Preprocessing the data and conducting summary statistics, while also generating visualizations to better understand the data.

```{r}
# Read the dataset
data <- read.csv("dataset11.csv")
data <- na.omit(data)
data$Qualityclass <- factor(data$Qualityclass, levels = c("Poor", "Good"))
str(data)
```

```{r}
# Scatterplot matrix with ggpairs()
scatterplot = data %>%
  dplyr::select(aroma, flavor, acidity, category_two_defects, altitude_mean_meters, Qualityclass)
ggpairs(scatterplot, aes(color = Qualityclass), title="Scatterplot matrix with ggpairs()") # 在pdf中显示奇怪
```

```{r}
scatterplot = data %>%
  dplyr::select(aroma, flavor, acidity, harvested, Qualityclass)
ggpairs(scatterplot, aes(color = Qualityclass), title="Scatterplot matrix with ggpairs()")
```

```{r}
#| label: tbl-table1
#| tbl-cap: Summary statistics
# Summary Statistics for 'aroma', 'flavor', and 'acidity' across different quality classes
data |>
  summarize('ar.Mean' = mean(aroma),
          'ar.Sd' = sd(aroma),
          'ar.Min' = min(aroma),
          'ar.Max' = max(aroma),
          'fl.Mean' = mean(flavor),
          'fl.Sd' = sd(flavor),
          'fl.Min' = min(flavor),
          'fl.Max' = max(flavor),
          'ac.Mean' = mean(acidity),
          'ac.Sd' = sd(acidity),
          'ac.Min' = min(acidity),
          'ac.Max' = max(acidity),
             .by = Qualityclass) |>
gt() |>
  fmt_number(decimals = 2) |>
  tab_spanner(
    label = "aroma",
    columns = c(ar.Mean, ar.Sd, ar.Min, ar.Max)
  ) |>
  tab_spanner(
    label = "flavor",
    columns = c(fl.Mean, fl.Sd, fl.Min, fl.Max)
  ) |>
  tab_spanner(
    label = "acidity",
    columns = c(ac.Mean, ac.Sd, ac.Min, ac.Max)
  ) 
```

```{r}
# Summary statistics for 'category_two_defects' and 'altitude_mean_meters' across different quality classes
data |>
  summarize('C.Mean' = mean(category_two_defects),
          'C.Sd' = sd(category_two_defects),
          'C.Min' = min(category_two_defects),
          'C.Max' = max(category_two_defects),
          'A.Mean' = mean(log(altitude_mean_meters)),
          'A.Sd' = sd(log(altitude_mean_meters)),
          'A.Min' = min(log(altitude_mean_meters)),
          'A.Max' = max(log(altitude_mean_meters)),
             .by = Qualityclass) |>
gt() |> 
  fmt_number(decimals = 2) |>
  tab_spanner(
    label = "Defects",
    columns = c(C.Mean, C.Sd, C.Min, C.Max)
  ) |>
  tab_spanner(
    label = "log_Altitude",
    columns = c(A.Mean, A.Sd, A.Min, A.Max)
  ) 
```

# Predictor Modeling and Evaluation

Modeling each predictor separately with the response variable to observe the individual impact of each feature on the quality of coffee.

## Country and Qualityclass

```{r}
model_full <- glm(Qualityclass ~ country_of_origin+aroma + flavor + acidity + category_two_defects + altitude_mean_meters+harvested, data = data, 
             family = binomial(link = "logit"))
model_full %>%
  summary()
```

```{r}
data <- data %>%
  mutate(country_category = ifelse(country_of_origin %in% c("Burundi", "Colombia", "India"), country_of_origin, "other")) %>%
  dplyr::select(country_of_origin,country_category,everything())
data$country_category <- factor(data$country_category, levels = c("Burundi","Colombia","India","other"))
str(data)
```

```{r}
# Select 'country_category' and 'Qualityclass' columns
data_country_category <- data %>%
          dplyr::select(country_category, Qualityclass)
data_country_category %>%
  tabyl(country_category, Qualityclass) %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>% 
  adorn_ns()
```

```{r}
# Create a barplot of 'country_category' across different 'Qualityclass' levels
ggplot(data_country_category, aes(x=Qualityclass, y = after_stat(prop), group=country_category, fill=country_category)) + 
    geom_bar(position="dodge", stat="count") +
    labs(y = "Proportion")
```

```{r}
model_country <- glm(Qualityclass ~ country_category, data = data_country_category, family = binomial(link = "logit"))
model_country %>%
  summary()
levels(data_country_category$Qualityclass)
levels(data_country_category$country_category)
```

```{r}
model_country_coef_logodds <- model_country %>%
                            summary() %>%
                            coef()
model_country_coef_logodds
confint_logodds <- confint(model_country) 
confint_logodds
```

```{r}
plot_model(model_country, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
model_country_coef_odds <- model_country %>%
      summary()%>%
      coef() %>%
       exp()
model_country_coef_odds
print(exp(confint_logodds))
```

```{r}
plot_model(model_country, show.values = TRUE,
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
data_country_category_after <- data_country_category %>%
            mutate(logodds.Good = predict(model_country, type = "response")) %>%
            mutate(odds.Good = exp(logodds.Good)) %>%
            mutate(probs.Good = fitted(model_country))
data_country_category_after
```

```{r}
plot_model(model_country, type = "pred",
           terms = c("country_category"))
```

## Aroma and Qualityclass

```{r}
# Select 'aroma' and 'Qualityclass' columns
data_aroma <- data %>%
            dplyr::select(aroma, Qualityclass)

# Create a boxplot of 'aroma' across different 'Qualityclass' levels
p1 <- ggplot(data = data_aroma, aes(x = Qualityclass, y = aroma, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "aroma")+ 
  theme(legend.position = "none")
p1
```

```{r}
# Calculate quartiles and determine lower and upper bounds
q1_aroma <- quantile(data_aroma$aroma, 0.25)
q3_aroma <- quantile(data_aroma$aroma, 0.75)
iqr_aroma <- q3_aroma - q1_aroma
lower_bound_aroma <- q1_aroma - 1.5 * iqr_aroma
upper_bound_aroma <- q3_aroma + 1.5 * iqr_aroma

# Filter 'aroma' within the calculated bounds
data_aroma_filtered <- data_aroma %>%
  filter(aroma >= lower_bound_aroma & aroma <= upper_bound_aroma)

# Create a boxplot of 'aroma'
p2 <- ggplot(data = data_aroma_filtered, aes(x = Qualityclass, y = aroma, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "aroma")+ 
  theme(legend.position = "none")
p2
```

```{r}
# Fit logistic regression model with 'aroma' predictor and 'Qualityclass' response
model1 <- glm(Qualityclass ~ aroma, data = data_aroma_filtered, 
             family = binomial(link = "logit"))
model1 %>%
  summary()
```

```{r}
# Calculate lower and upper bounds for 'aroma' log-odds
mod1.coef.logodds <- model1 %>%
                      summary() %>%
                      coef()
aroma.logodds.lower <- mod1.coef.logodds["aroma", "Estimate"] - 
                      1.96 * mod1.coef.logodds["aroma", "Std. Error"]
aroma.logodds.upper <- mod1.coef.logodds["aroma", "Estimate"] + 
                      1.96 * mod1.coef.logodds["aroma", "Std. Error"]

# Display the confidence interval
paste("(", aroma.logodds.lower, ",", aroma.logodds.upper, ")")

# Plot log-odds of being a good instructor
plot_model(model1, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Calculate lower and upper bounds for 'aroma' odds
exp(mod1.coef.logodds) # 该输出可以不用显示
aroma.odds.lower <- exp(aroma.logodds.lower)
aroma.odds.upper <- exp(aroma.logodds.upper)

# Display the confidence interval
paste("(", aroma.odds.lower, ",", aroma.odds.upper, ")")

# Plot odds of being a good instructor
plot_model(model1, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_aroma_filtered_after <- data_aroma_filtered %>%
                  mutate(logodds.Good = predict(model1, type = "response")) %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model1))

# Plot the relationship between 'aroma' and probability of being a good instructor
ggplot(data = data_aroma_filtered_after, aes(x = aroma, y = probs.Good)) +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial"), 
              se = FALSE) +
  labs(x = "aroma", y = "Probability of instructor being Good")
```

## Flavor and Qualityclass

```{r}
# Select 'flavor' and 'Qualityclass' columns
data_flavor <- data %>%
            dplyr::select(flavor, Qualityclass)

# Create a boxplot of 'flavor' across different 'Qualityclass' levels
p3 <- ggplot(data = data_flavor, aes(x = Qualityclass, y = flavor, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "flavor")+ 
  theme(legend.position = "none")
p3
```

```{r}
# Calculate quartiles and determine lower and upper bounds
q1_flavor <- quantile(data_flavor$flavor, 0.25)
q3_flavor <- quantile(data_flavor$flavor, 0.75)
iqr_flavor <- q3_flavor - q1_flavor
lower_bound_flavor <- q1_flavor - 1.5 * iqr_flavor
upper_bound_flavor <- q3_flavor + 1.5 * iqr_flavor

# Filter 'flavor' within the calculated bounds
data_flavor_filtered <- data_flavor %>%
  filter(flavor >= lower_bound_flavor & flavor <= upper_bound_flavor)

# Create a boxplot of 'flavor'
p4 <- ggplot(data = data_flavor_filtered, aes(x = Qualityclass, y = flavor, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "flavor")+ 
  theme(legend.position = "none")
p4
```

```{r}
# Fit logistic regression model with 'flavor' predictor and 'Qualityclass' response
model2 <- glm(Qualityclass ~ flavor, data = data_flavor_filtered, 
             family = binomial(link = "logit"))
model2 %>%
  summary()
```

```{r}
# Calculate lower and upper bounds for 'flavor' log-odds
mod2.coef.logodds <- model2 %>%
                      summary() %>%
                      coef()
flavor.logodds.lower <- mod2.coef.logodds["flavor", "Estimate"] - 
                      1.96 * mod2.coef.logodds["flavor", "Std. Error"]
flavor.logodds.upper <- mod2.coef.logodds["flavor", "Estimate"] + 
                      1.96 * mod2.coef.logodds["flavor", "Std. Error"]

# Display the confidence interval
paste("(", flavor.logodds.lower, ",", flavor.logodds.upper, ")")

# Plot log-odds of being a good instructor
plot_model(model2, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Calculate lower and upper bounds for 'flavor' odds
exp(mod2.coef.logodds)
flavor.odds.lower <- exp(flavor.logodds.lower)
flavor.odds.upper <- exp(flavor.logodds.upper)

# Display the confidence interval
paste("(", flavor.odds.lower, ",", flavor.odds.upper, ")")

# Plot odds of being a good instructor
plot_model(model2, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_flavor_filtered_after <- data_flavor_filtered %>%
                  mutate(logodds.Good = predict(model2, type = "response")) %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model2))

# Plot the relationship between 'flavor' and probability of being a good instructor
ggplot(data = data_flavor_filtered_after, aes(x = flavor, y = probs.Good)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "flavor", y = "Probability of instructor being Good")
```

## Acidity and Qualityclass

```{r}
# Select 'acidity' and 'Qualityclass' columns
data_acidity <- data %>%
            dplyr::select(acidity, Qualityclass)

# Create a boxplot of 'acidity' across different 'Qualityclass' levels
p5 <- ggplot(data = data_acidity, aes(x = Qualityclass, y = acidity, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "acidity")+ 
  theme(legend.position = "none")
p5
```

```{r}
# Calculate quartiles and determine lower and upper bounds
q1_acidity <- quantile(data_acidity$acidity, 0.25)
q3_acidity <- quantile(data_acidity$acidity, 0.75)
iqr_acidity <- q3_acidity - q1_acidity
lower_bound_acidity <- q1_acidity - 1.5 * iqr_acidity
upper_bound_acidity <- q3_acidity + 1.5 * iqr_acidity

# Filter 'acidity' within the calculated bounds
data_acidity_filtered <- data_acidity %>%
  filter(acidity >= lower_bound_acidity & acidity <= upper_bound_acidity)

# Create a boxplot of 'acidity'
p6 <- ggplot(data = data_acidity_filtered, aes(x = Qualityclass, y = acidity, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "acidity")+ 
  theme(legend.position = "none")
p6
```

```{r}
# Fit logistic regression model with 'acidity' predictor and 'Qualityclass' response
model3 <- glm(Qualityclass ~ acidity, data = data_acidity_filtered, 
             family = binomial(link = "logit"))
model3 %>%
  summary()
```

```{r}
# Calculate lower and upper bounds for 'acidity' log-odds
mod3.coef.logodds <- model3 %>%
                      summary() %>%
                      coef()
acidity.logodds.lower <- mod3.coef.logodds["acidity", "Estimate"] - 
                      1.96 * mod3.coef.logodds["acidity", "Std. Error"]
acidity.logodds.upper <- mod3.coef.logodds["acidity", "Estimate"] + 
                      1.96 * mod3.coef.logodds["acidity", "Std. Error"]

# Display the confidence interval
paste("(", acidity.logodds.lower, ",", acidity.logodds.upper, ")")

# Plot log-odds of being a good instructor
plot_model(model3, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Calculate lower and upper bounds for 'acidity' odds
exp(mod3.coef.logodds)
acidity.odds.lower <- exp(acidity.logodds.lower)
acidity.odds.upper <- exp(acidity.logodds.upper)

# Display the confidence interval
paste("(", acidity.odds.lower, ",", acidity.odds.upper, ")")

# Plot odds of being a good instructor
plot_model(model3, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_acidity_filtered_after <- data_acidity_filtered %>%
                  mutate(logodds.Good = predict(model3, type = "response")) %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model3))

# Plot the relationship between 'acidity' and probability of being a good instructor
ggplot(data = data_acidity_filtered_after, aes(x = acidity, y = probs.Good)) +
  geom_smooth(method ="glm", 
              method.args = list(family = "binomial"), 
              se = FALSE) +
  labs(x = "acidity", y = "Probability of instructor being Good")
```

## Altitude mean meters and Qualityclass

```{r}
# Select 'altitude_mean_meters' and 'Qualityclass' columns
data_altitude <- data %>%
            dplyr::select(altitude_mean_meters, Qualityclass)

# Create a boxplot of 'altitude_mean_meters' across different 'Qualityclass' levels
p7 <- ggplot(data = data_altitude, aes(x = Qualityclass, y = altitude_mean_meters, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "altitude")+ 
  theme(legend.position = "none")
p7
```

```{r}
# Calculate quartiles and determine lower and upper bounds
q1_altitude <- quantile(data_altitude$altitude_mean_meters, 0.25)
q3_altitude <- quantile(data_altitude$altitude_mean_meters, 0.75)
iqr_altitude <- q3_altitude - q1_altitude
lower_bound_altitude <- q1_altitude - 1.5 * iqr_altitude
upper_bound_altitude <- q3_altitude + 1.5 * iqr_altitude

# Filter 'altitude_mean_meters' within the calculated bounds
data_altitude_filtered <- data_altitude %>%
  filter(altitude_mean_meters >= lower_bound_altitude & altitude_mean_meters <= upper_bound_altitude)

# Create a boxplot of 'altitude_mean_meters'
p8 <- ggplot(data = data_altitude_filtered, aes(x = Qualityclass, y = altitude_mean_meters, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "altitude")+ 
  theme(legend.position = "none")
p8
```

```{r}
# Fit logistic regression model with 'altitude_mean_meters' predictor and 'Qualityclass' response
model4 <- glm(Qualityclass ~ altitude_mean_meters, data = data_altitude_filtered, 
             family = binomial(link = "logit"))
model4 %>%
  summary()
```

```{r}
# Calculate lower and upper bounds for 'altitude_mean_meters' log-odds
mod4.coef.logodds <- model4 %>%
                      summary() %>%
                      coef()
altitude.logodds.lower <- mod4.coef.logodds["altitude_mean_meters", "Estimate"] - 
                      1.96 * mod4.coef.logodds["altitude_mean_meters", "Std. Error"]
altitude.logodds.upper <- mod4.coef.logodds["altitude_mean_meters", "Estimate"] + 
                      1.96 * mod4.coef.logodds["altitude_mean_meters", "Std. Error"]

# Display the confidence interval
paste("(", altitude.logodds.lower, ",", altitude.logodds.upper, ")")

# Plot log-odds of being a good instructor
plot_model(model4, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Calculate lower and upper bounds for 'altitude_mean_meters' odds
exp(mod4.coef.logodds)
altitude.odds.lower <- exp(altitude.logodds.lower)
altitude.odds.upper <- exp(altitude.logodds.upper)

# Display the confidence interval
paste("(", altitude.odds.lower, ",", altitude.odds.upper, ")")

# Plot odds of being a good instructor
plot_model(model4, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_altitude_filtered_after <- data_altitude_filtered %>%
                  mutate(logodds.Good = predict(model4), type = "response") %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model4))

# Plot the relationship between 'altitude_mean_meters' and probability of being a good instructor
ggplot(data = data_altitude_filtered_after, aes(x = altitude_mean_meters, y = probs.Good)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "altitude", y = "Probability of instructor being Good")
```

## Category 2 type defects and Qualityclass

```{r}
# Select 'category_two_defects' and 'Qualityclass' columns
data_defects <- data %>%
              dplyr::select(category_two_defects, Qualityclass)

# Create a boxplot of 'category_two_defects' across different 'Qualityclass' levels
p9 <- ggplot(data = data_defects, aes(x = Qualityclass, y = category_two_defects, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "defects")+ 
  theme(legend.position = "none")
p9
```

```{r}
# Calculate quartiles and determine lower and upper bounds
q1_defect <- quantile(data_defects$category_two_defects, 0.25)
q3_defect <- quantile(data_defects$category_two_defects, 0.75)
iqr_defect <- q3_defect - q1_defect
lower_bound_defect <- q1_defect - 1.5 * iqr_defect
upper_bound_defect <- q3_defect + 1.5 * iqr_defect

# Filter 'category_two_defects' within the calculated bounds
data_defects_filtered <- data_defects %>%
  filter(category_two_defects >= lower_bound_defect & category_two_defects <= upper_bound_defect)

# Create a boxplot of 'category_two_defects'
p10 <- ggplot(data = data_defects_filtered, aes(x = Qualityclass, y = category_two_defects, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "defects")+ 
  theme(legend.position = "none")
p10
```

```{r}
# Fit logistic regression model with 'category_two_defects' predictor and 'Qualityclass' response
model5 <- glm(Qualityclass ~ category_two_defects, data = data_defects_filtered, 
             family = binomial(link = "logit"))
model5 %>%
  summary()
```

```{r}
# Calculate lower and upper bounds for 'category_two_defects' log-odds
mod5.coef.logodds <- model5 %>%
                      summary() %>%
                      coef()
defects.logodds.lower <- mod5.coef.logodds["category_two_defects", "Estimate"] - 
                      1.96 * mod5.coef.logodds["category_two_defects", "Std. Error"]
defects.logodds.upper <- mod5.coef.logodds["category_two_defects", "Estimate"] + 
                      1.96 * mod5.coef.logodds["category_two_defects", "Std. Error"]

# Display the confidence interval
paste("(", defects.logodds.lower, ",", defects.logodds.upper, ")")

# Plot log-odds of being a good instructor
plot_model(model5, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Calculate lower and upper bounds for 'category_two_defects' odds
exp(mod5.coef.logodds)
defects.odds.lower <- exp(defects.logodds.lower)
defects.odds.upper <- exp(defects.logodds.upper)

# Display the confidence interval
paste("(", defects.odds.lower, ",", defects.odds.upper, ")")

# Plot odds of being a good instructor
plot_model(model5, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_defects_filtered_after <- data_defects_filtered %>%
                  mutate(logodds.Good = predict(model5, type = "response")) %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model5))

# Plot the relationship between 'category_two_defects' and probability of being a good instructor
ggplot(data = data_defects_filtered_after, aes(x = category_two_defects, y = probs.Good)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "defects", y = "Probability of instructor being Good")
```

## Harvested and Qualityclass

```{r}
# Select 'harvested' and 'Qualityclass' columns
data_harvested <- data %>%
            dplyr::select(harvested, Qualityclass)

# Create a boxplot of 'harvested' across different 'Qualityclass' levels
p11 <- ggplot(data = data_harvested, aes(x = Qualityclass, y = harvested, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "harvested")+ 
  theme(legend.position = "none")
p11
```

```{r}
model6 <- glm(Qualityclass ~ harvested, data = data_harvested, 
             family = binomial(link = "logit"))
model6 %>%
  summary()
```

```{r}
model6_coef_logodds <- model6 %>%
                            summary() %>%
                            coef()
model6_coef_logodds
confint_logodds <- confint(model6) 
confint_logodds
```

```{r}
# Plot log-odds of being a good instructor
plot_model(model6, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
model6_coef_odds <- model6 %>%
      summary()%>%
      coef() %>%
       exp()
model6_coef_odds
print(exp(confint_logodds))
```

```{r}
# Plot log-odds of being a good instructor
plot_model(model6, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted probabilities
data_harvested_after <- data_harvested %>%
                  mutate(logodds.Good = predict(model6, type = "response")) %>%
                  mutate(odds.Good = exp(logodds.Good)) %>%
                  mutate(probs.Good = fitted(model6))

# Plot the relationship between 'category_two_defects' and probability of being a good instructor
ggplot(data_harvested_after, aes(x = harvested, y = probs.Good)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "harvested", y = "Probability of instructor being Good")
```

# a

```{r}
model_country_aroma_flavor <- glm(Qualityclass ~ country_category+aroma+flavor, data = data, 
             family = binomial(link = "logit"))
plot_model(model_country_aroma_flavor, type = "pred",
           terms = c("aroma","flavor","country_category"))
```

```{r}
model_country_acidity_altitude <- glm(Qualityclass ~ country_category+acidity+altitude_mean_meters, data = data, 
             family = binomial(link = "logit"))
plot_model(model_country_acidity_altitude, type = "pred",
           terms = c("acidity","altitude_mean_meters","country_category"))
```

```{r}
model_aroma_flavor_acidity <- glm(Qualityclass ~ country_category+aroma+category_two_defects, data = data, family = binomial(link = "logit"))
plot_model1 <- plot_model(model_aroma_flavor_acidity, type = "pred",
           terms = c("category_two_defects","aroma","country_category"))
plot_model1
```

```{r}
plot_model2 <-plot_model(model_aroma_flavor_acidity_altitude, type = "pred",
           terms = c("flavor","aroma","acidity","altitude_mean_meters"))
plot_model2
```

```{r}

```

# Stepwise Predictor Reduction in Model Fitting

```{r}
# Arrange multiple plots
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, ncol=2)
```

```{r}
model_full_after <- glm(Qualityclass ~ country_category+aroma + flavor + acidity + category_two_defects + altitude_mean_meters+harvested, data = data, 
             family = binomial(link = "logit"))
model_full_after %>%
  summary()
```

```{r}
model_full_after_summary <- glance(glm(Qualityclass ~ country_category+aroma + flavor + acidity + category_two_defects + altitude_mean_meters+harvested, data = data, 
             family = binomial(link = "logit")))
kable(model_full_after_summary,digits = 2)
```

```{r}
model_full_after1 <- glm(Qualityclass ~ aroma + flavor + acidity +harvested, data = data, family = binomial(link = "logit"))
model_full_after1 %>%
  summary()
```

```{r}
model_full_after1_summary <- glance(glm(Qualityclass ~ aroma + flavor + acidity +harvested, data = data, 
             family = binomial(link = "logit")))
kable(model_full_after1_summary,digits = 2)
```

```{r}
stepAIC(model_full_after1)
```

```{r}
model_full_after_step_summary <- glance(glm(Qualityclass ~ country_category+aroma + flavor + acidity + category_two_defects+harvested, data = data, 
             family = binomial(link = "logit")))
kable(model_full_after_step_summary,digits = 2)
```

```{r}
# Fit logistic regression model with all predictors
model_full1 <- glm(Qualityclass ~ aroma + flavor + acidity + category_two_defects + altitude_mean_meters, data = data, 
             family = binomial(link = "logit"))
model_full1 %>%
  summary()

# Summary statistics for the model
model_full1_summary <- glance(glm(Qualityclass ~ aroma + flavor + acidity + category_two_defects + altitude_mean_meters, data = data, 
             family = binomial(link = "logit")))
kable(model_full1_summary,digits = 2)
```

Due to the non-significant p-values of 'category two defects' and 'altitude mean meters', these two variables are removed.

```{r}
# Fit logistic regression model with 'aroma', 'flavor', and 'acidity' predictors
model_full2 <- glm(Qualityclass ~ aroma + flavor + acidity, data = data, 
             family = binomial(link = "logit"))
model_full2 %>%
  summary()

# Summary statistics for the model
model_full2_summary <- glance(glm(Qualityclass ~ aroma + flavor + acidity, data = data, 
             family = binomial(link = "logit")))
kable(model_full2_summary,digits = 2)
```

Try reducing one predictor to see if it improves the model.

```{r}
# Fit logistic regression model with 'flavor' and 'acidity' predictors
model_full3 <- glm(Qualityclass ~ flavor + acidity, data = data, 
             family = binomial(link = "logit"))
model_full3 %>%
  summary()

# Summary statistics for the model
model_full3_summary <- glance(glm(Qualityclass ~ flavor + acidity, data = data, 
             family = binomial(link = "logit")))
kable(model_full3_summary,digits = 2)
```

```{r}
# Fit logistic regression model with 'aroma' and 'acidity' predictors
model_full4 <- glm(Qualityclass ~ aroma + acidity, data = data, 
             family = binomial(link = "logit"))
model_full4 %>%
  summary()

# Summary statistics for the model
model_full4_summary <- glance(glm(Qualityclass ~ aroma + acidity, data = data, 
             family = binomial(link = "logit")))
kable(model_full4_summary,digits = 2)
```

```{r}
# Fit logistic regression model with 'aroma' and 'flavor' predictors
model_full5 <- glm(Qualityclass ~ aroma + flavor, data = data, 
             family = binomial(link = "logit"))
model_full5 %>%
  summary()

# Summary statistics for the model
model_full5_summary <- glance(glm(Qualityclass ~ aroma + flavor, data = data, 
             family = binomial(link = "logit")))
kable(model_full5_summary,digits = 2)
```

Based on the AIC and BIC values of the above models, it can be concluded that the model with 'aroma', 'flavor', and 'acidity' as predictors is optimal.

Plotting the log-odds and odds of the final model allows for a visual representation of the relationship between the predictors and the response variable.

```{r}
# Plot log-odds of being a good instructor for model_full2
plot_model(model_full2, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Good instructor)", show.p = FALSE)

# Plot odds of being a good instructor for model_full2
plot_model(model_full2, show.values = TRUE, 
           title = "Odds (Good instructor)", show.p = FALSE)
```

```{r}
# Add predicted log-odds, odds, and probabilities of being a good instructor to the data
data_after <- data %>%
          mutate(logodds.Good = round(predict(model_full2), 4)) %>%
          mutate(odds.Good = round(exp(logodds.Good),4)) %>%
          mutate(probs.Good = round(fitted(model_full2),4))

# Select the final predictors and calculate the correlation matrix
data_after1 <- data_after %>% 
   select(aroma, flavor, acidity)
data_after1 %>%
  cor()
```

# Principal Component Analysis

Based on the correlation matrix above, it is evident that the predictors exhibit high correlation. Therefore, we adopt principal component analysis (PCA) to help address multicollinearity, thereby enhancing the stability and interpretability of the model.

```{r}
# Perform principal component analysis (PCA)
data_pca <- data %>%
  select(aroma, flavor, acidity, Qualityclass)
data_scaled <- scale(data_pca[, -4])
pca_result <- prcomp(data_scaled)
pca_result
summary(pca_result)

# Predict PCA components
pca_result_selected <- predict(pca_result, newdata = data_scaled)
pca_result_selected_df <- as.data.frame(pca_result_selected)

# Combine PCA components with Qualityclass
data_pca_final <- pca_result_selected_df %>%
  mutate(Qualityclass = data_pca$Qualityclass)

# Fit logistic regression model with PCA components
pca_model <- glm(Qualityclass ~ ., data = data_pca_final, family = binomial(link = "logit"))
pca_model_summary <- glance(pca_model)
kable(pca_model_summary,digits =2)
```

The cumulative proportion of the three predictor variables adds up to 1, indicating that these three principal components fully explain the variability in the original data without losing information. Therefore, adopting principal component analysis is justified.

Meanwhile, the AIC and BIC values have remained unchanged, and they are still significantly lower than those of other models. This suggests that the three predictors in the original model have already provided the best explanatory power for the response variable. Therefore, the model with three predictors: 'aroma', 'flavor', and 'acidity' is optimal.

$$
\text{Qualityclass} = \beta_0 + \beta_1 \times \text{aroma} + \beta_2 \times \text{flavor} + \beta_3 \times \text{acidity} + \epsilon
$$

-   $Qualityclass$ is the response variable
-   $aroma$, $flavor$, and $acidity$ are the predictor variables
-   $\beta_0$ to $\beta_3$ are the coefficients of the model
-   $\epsilon$ is the error term
